# LocalAIAgentWithRAG

### Run application
- python -m venv venv
- source venv/bin/activate
- pip install -r requirements.txt
- curl -fsSL https://ollama.com/install.sh | sh (install ollama)
- ollama pull llama3.2 (model)
- ollama pull mxbai-embed-large (embeding model)
- 